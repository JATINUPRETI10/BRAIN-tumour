{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM8jjH3RpNHQwq/FPHzCJaI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JATINUPRETI10/BRAIN-tumour/blob/main/Brain_tumour_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJH2YLneJKTz",
        "outputId": "5f5eb8e4-d276-476b-ebea-5184ce3de7be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# importing library"
      ],
      "metadata": {
        "id": "zKQLGVHpv7B8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUVpUIyFqgWP"
      },
      "outputs": [],
      "source": [
        "import os #for directory and file\n",
        "import numpy as np # for maths opertaion and handling image array\n",
        "import random #for generating random values for augmentation\n",
        "from PIL import Image #for image handling\n",
        "from PIL import ImageEnhance#for better image\n",
        "from tensorflow.keras.preprocessing.image import load_img#for loading image\n",
        "from tensorflow.keras.models import Sequential#for model building\n",
        "from tensorflow.keras.layers import Input ,Flatten,Dropout,Dense#for model layers\n",
        "from tensorflow.keras.optimizers import Adam#for optimizer\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from sklearn.utils import shuffle # for shuffling data\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load dataset"
      ],
      "metadata": {
        "id": "ozvpWhnsKWjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# directories for train and test\n",
        "train_dir = '/content/drive/MyDrive/BT_data/Training/'\n",
        "test_dir = '/content/drive/MyDrive/BT_data/Testing/'\n",
        "#for train image\n",
        "train_paths=[]#train image\n",
        "train_labels=[]#label of train image\n",
        "\n",
        "for label in os.listdir(train_dir):\n",
        "  # Corrected the typo 'listdr' to 'listdir'\n",
        "  for image in os.listdir(os.path.join(train_dir,label)):\n",
        "    train_paths.append(os.path.join(train_dir,label,image))\n",
        "    train_labels.append(label)\n",
        "train_paths,train_labels=shuffle(train_paths,train_labels)\n",
        "\n",
        "#for test image\n",
        "test_paths=[]#train image\n",
        "test_labels=[]#label of train image\n",
        "\n",
        "for label in os.listdir(test_dir):\n",
        "  # Corrected the typo 'listdr' to 'listdir'\n",
        "  for image in os.listdir(os.path.join(test_dir,label)):\n",
        "    test_paths.append(os.path.join(test_dir,label,image))\n",
        "    test_labels.append(label)\n",
        "test_paths,test_labels=shuffle(test_paths,test_labels)"
      ],
      "metadata": {
        "id": "p5cfoW5bu0s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# image preprocessing"
      ],
      "metadata": {
        "id": "iorhyNbmkmt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data augmentation in machine learning is the process of artificially generating new data from existing data to train machine learning models, primarily to increase the size and diversity of the training dataset.\n",
        "#image augmentation func\n",
        "def augement_image(image):\n",
        "  image=Image.fromarray(np.uint8(image))# convert image to pillow func\n",
        "  image=ImageEnhance.Brightness(image).enhance(random.uniform(0.8,1.2))#brightness and contrast will be nc in 0.8 to 1.2\n",
        "  image=ImageEnhance.Contrast(image).enhance(random.uniform(0.8,1.2))# if greather then 1 then dark or if less then 1 then inc\n",
        "  image=np.array(image)/255#normalistaion(bring the imnage pixel in 0,1)\n",
        "  return image\n",
        "\n",
        "# load image and aplly augmetation\n",
        "def open_images(paths):\n",
        "  images=[]\n",
        "  for path in paths:\n",
        "    image=load_img(path,target_size=(128,128))\n",
        "    image=augement_image(image)\n",
        "    images.append(image)\n",
        "  return np.array(images)\n",
        "\n",
        "# encoder labels(convert labels into int)\n",
        "def encode_label(labels):\n",
        "  unique_labels=os.listdir(train_dir)\n",
        "  encoded=[unique_labels.index(label) for label in labels]\n",
        "  return np.array(encoded)\n",
        "#data generator in batches\n",
        "def datagen(paths,labels,batch_size=12,epochs=1):\n",
        "   for _ in range(epochs):\n",
        "        for i in range(0, len(paths), batch_size):\n",
        "            batch_paths = paths[i:i + batch_size]\n",
        "            batch_images = open_images(batch_paths)  # Open and augment images\n",
        "            batch_labels = labels[i:i + batch_size]\n",
        "            batch_labels = encode_label(batch_labels)  # Encode labels\n",
        "            yield batch_images, batch_labels  # Yield the batch"
      ],
      "metadata": {
        "id": "y7sWvIecKHlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model preprocessing with vgg16\n"
      ],
      "metadata": {
        "id": "4seknUw9r3BL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size=128 #(px)\n",
        "#parameter base_model contain pretrain model vgg16 which we will be using with our input and layers\n",
        "#include_top=False means we are not using its layers and weights imagenet means model work best in this weight\n",
        "base_model=VGG16(input_shape=(image_size,image_size,3),include_top=False,weights=\"imagenet\")\n",
        "\n",
        "# Freeze all layers of the VGG16 base model\n",
        "for layers in base_model.layers:\n",
        "  layers.trainable=False\n",
        "  #only take last layers of the model\n",
        "base_model.layers[-2].trainable=True\n",
        "base_model.layers[-3].trainable=True\n",
        "base_model.layers[-4].trainable=True\n",
        "\n",
        "# build final model\n",
        "model=Sequential()\n",
        "model.add(Input(shape=(image_size,image_size,3)))# input layer\n",
        "model.add(base_model)# vgg16 model\n",
        "model.add(Flatten())#flatten the output layer\n",
        "model.add(Dropout(0.3))#dropout layer after input layer to drop neuron in nxt layer to reduce overfitting\n",
        "model.add(Dense(128,activation='relu'))#hidden layer\n",
        "model.add(Dropout(0.2))#dropout layer after hidden layer to drop neuron in nxt layer to reduce overfitting\n",
        "model.add(Dense(len(os.listdir(train_dir)),activation='softmax'))\n",
        "\n",
        "\n",
        "#compile\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "             metrics=['sparse_categorical_accuracy'] )\n",
        "\n",
        " #Parameters\n",
        "batch_size = 20\n",
        "steps = int(len(train_paths) / batch_size)  # Steps per epoch\n",
        "epochs = 1\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(datagen(train_paths, train_labels, batch_size=batch_size, epochs=epochs),\n",
        "                  epochs=epochs,  steps_per_epoch=steps\n",
        "                    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxXm6cHBryQ1",
        "outputId": "9c5e529a-ef57-42b7-f322-098d4ffe2c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m987s\u001b[0m 3s/step - loss: 0.6535 - sparse_categorical_accuracy: 0.7381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model classification report"
      ],
      "metadata": {
        "id": "eQZ4tZ9S4Xot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "# 1. Prediction on test data\n",
        "test_images = open_images(test_paths)  # Load and augment test images\n",
        "test_labels_encoded = encode_label(test_labels)  # Encode the test labels\n",
        "\n",
        "# Predict using the trained model\n",
        "test_predictions = model.predict(test_images)\n",
        "\n",
        "# 2. Classification Report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(test_labels_encoded, np.argmax(test_predictions, axis=1)))"
      ],
      "metadata": {
        "id": "Fwvgimz9tLhQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "7546ed4c-a248-4404-b546-18c2f0ea4f61",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'open_images' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b1dde068b790>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 1. Prediction on test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_paths\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load and augment test images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtest_labels_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Encode the test labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'open_images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save model"
      ],
      "metadata": {
        "id": "EL_fYj9w6bVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "kzIWxjV54eXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# mri detect sys"
      ],
      "metadata": {
        "id": "HLraS28XWbxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Class labels\n",
        "class_labels = ['pituitary', 'glioma', 'notumor', 'meningioma']\n",
        "\n",
        "def detect_and_display(img_path, model, image_size=128):\n",
        "    \"\"\"\n",
        "    Function to detect tumor and display results.\n",
        "    If no tumor is detected, it displays \"No Tumor\".\n",
        "    Otherwise, it shows the predicted tumor class and confidence.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load and preprocess the image\n",
        "        img = load_img(img_path, target_size=(image_size, image_size))\n",
        "        img_array = img_to_array(img) / 255.0  # Normalize pixel values\n",
        "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "        # Make a prediction\n",
        "        predictions = model.predict(img_array)\n",
        "        predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
        "        confidence_score = np.max(predictions, axis=1)[0]\n",
        "\n",
        "        # Determine the class\n",
        "        if class_labels[predicted_class_index] == 'notumor':\n",
        "            result = \"No Tumor\"\n",
        "        else:\n",
        "            result = f\"Tumor: {class_labels[predicted_class_index]}\"\n",
        "\n",
        "        # Display the image with the prediction\n",
        "        plt.imshow(load_img(img_path))\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"{result} (Confidence: {confidence_score * 100:.2f}%)\")\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error processing the image:\", str(e))"
      ],
      "metadata": {
        "id": "RMR7HDkiWaqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "image_path = '/content/drive/MyDrive/BT_data/Testing/meningioma/Te-meTr_0001.jpg'  # Provide the path to your new image\n",
        "detect_and_display(image_path, model)"
      ],
      "metadata": {
        "id": "rhYOnfmSWwKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "image_path = '/content/drive/MyDrive/BT_data/Testing/notumor/Te-noTr_0004.jpg'  # Provide the path to your new image\n",
        "detect_and_display(image_path, model)"
      ],
      "metadata": {
        "id": "iKlp7g8xYtsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gH37Yzu0YtaV"
      }
    }
  ]
}